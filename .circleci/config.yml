version: 2.1

orbs:
  aws-cli: circleci/aws-cli@2.0.3
#  ------------------------------------------------------------------------------------------------------------------------------------------
#  defaults (like global variables dubstiuted below)
#  ------------------------------------------------------------------------------------------------------------------------------------------
docvarnode: &dok_node
    docker:
      - image: circleci/node:13.8.0

docvaraws: &dok_awscli
    docker:
      - image: amazon/aws-cli    

docansibl: &dok_ansible
    docker:
      - image: python:3.7-alpine3.11 

#  ------------------------------------------------------------------------------------------------------------------------------------------
#  list of parameters
#  ------------------------------------------------------------------------------------------------------------------------------------------

parameters:
  workflow-id:
    type: string
    default: "${CIRCLE_WORKFLOW_ID}"

#  ------------------------------------------------------------------------------------------------------------------------------------------
#  list of commands used in job 
#
#  ------------------------------------------------------------------------------------------------------------------------------------------

commands:
# ----------------------------------   to destroy the aws infra ----------------------------------------------------------------------------
  destroy-environment:
    description: Destroy back-end and front-end cloudformation stacks given a workflow ID. 
    parameters:
      workflow_id:
        type: string  
    steps:
      - run:
          name: Destroy environments
          when: on_fail          
          command: |
            apk add --no-cache python3 py3-pip \
            && pip3 install --upgrade pip \
            && pip3 install awscli \
            && rm -rf /var/cache/apk/*
            echo "Destroying environment: <<parameters.workflow_id>> "
            aws cloudformation delete-stack --stack-name udapeople-backend-<<parameters.workflow_id>>
            aws s3 rm s3://udapeople-<<parameters.workflow_id>> --recursive
            aws cloudformation delete-stack --stack-name udapeople-frontend-<<parameters.workflow_id>>
            
# ----------------------------------   to reverse the migration   --------------------------------------------------------------------------
  revert-migrations:
    description: Revert the last migration if successfully run in the current workflow.    
    parameters:
      workflow_id:
        type: string
    steps:
      - run:
          name: Revert migrations
          when: on_fail
          working_directory: ./backend
          command: |
              status=$(curl -H "token: 58c78a8b-64a1-4bd9-8527-e0f897b1d02a" --request GET https://api.memstash.io/values/migration_status__<<parameters.workflow_id>>)
              echo $status
              if [[ "$status" == "db_success" ]]
              then
                apk add --update tar gzip curl nodejs npm
                npm run migrations:revert
              fi
              
              
#  ------------------------------------------------------------------------------------------------------------------------------------------
#    Jobs list start from here    
#  ------------------------------------------------------------------------------------------------------------------------------------------

jobs:

# -----------------------------  Build front end ----------------------
  build-frontend:
    <<: *dok_node
    environment: 
      MY_STEP_NAME: "Build frontend"
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Build front-end
          working_directory: ./frontend
          command:             
            npm i
            npm run build                        
      - save_cache:
          paths: [frontend/node_modules]
          key: frontend-build 

# -----------------------------  Build back end ----------------------
  build-backend:
    <<: *dok_node
    environment: 
      MY_STEP_NAME: "Build backend"
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Back-end build
          working_directory: ./backend
          command: | 
            npm cache clean \
            && npm i \
            && npm run build             
      - save_cache:
          paths: [backend/node_modules]
          key: backend-build
          
# -----------------------------  Test front end  ----------------------
  test-frontend:
    <<: *dok_node
    environment: 
      MY_STEP_NAME: "Test frontend"
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]
      - run:
          name: Run tests with JUnit 
          working_directory: ./frontend
          command:               
              npm i
              npm test
          environment:
            JEST_JUNIT_OUTPUT_DIR: ./testres
      - store_test_results:
          path: ./frontend/testres
      - store_artifacts:
          path: ./frontend/testres

# -----------------------------  Test back end  ----------------------                
  test-backend:
    <<: *dok_node
    environment: 
      MY_STEP_NAME: "Test backend"    
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Run tests with JUnit
          working_directory: ./backend
          command: 
              npm i
              npm test
          environment:
            JEST_JUNIT_OUTPUT_DIR: ./testres
      - store_test_results:
          path: ./backend/testres
      - store_artifacts:
          path: ./backend/testres
          
# -----------------------------  Test front end for security ----------            
  scan-frontend:
    <<: *dok_node
    environment: 
      MY_STEP_NAME: "Security scan frontend"    
    steps:
      - checkout
      - restore_cache:
          keys: [frontend-build]      
      - run:
          name: frontend security check
          working_directory: ./frontend
          command: 
            npm i
            npm audit fix --audit-level=critical --force

# -----------------------------  Test back end for security ----------            
  scan-backend:
    <<: *dok_node
    environment: 
      MY_STEP_NAME: "Security scan backend"    
    steps:
      - checkout  
      - restore_cache:
          keys: [backend-build]          
      - run:
          name: backend security check
          working_directory: ./backend
          command: 
            npm audit fix --audit-level=critical --force

#   -------------------------------------------------------------------------
#                   AWS  INFRA. PART start from here
#   -------------------------------------------------------------------------

  deploy-infrastructure:
    <<: *dok_awscli
    environment: 
      MY_STEP_NAME: "Deploy Infrastructure"     
    steps:
      - checkout
      - run:
          name: install dependancy
          command: yum install -y tar gzip
      - run:
          name: deploy back-end infrastructure
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/backend.yml \
              --stack-name udapeople-backend-${CIRCLE_WORKFLOW_ID:0:7} \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}" \
              --region us-west-2
      - run:
          name: deploy front-end infrastructure
          command: |
            aws cloudformation deploy \
              --template-file .circleci/files/frontend.yml \
              --stack-name udapeople-frontend-${CIRCLE_WORKFLOW_ID:0:7} \
              --parameter-overrides ID="${CIRCLE_WORKFLOW_ID:0:7}" \
              --region us-west-2
      - run:
          name: Add back-end ip to ansible inventory
          command: |
            BACKEND_AWS_PUBLIC_IP=$(aws ec2 describe-instances \
              --query 'Reservations[*].Instances[*].PublicIpAddress' \
              --output text)
            echo "http://$BACKEND_AWS_PUBLIC_IP:3030" > ~/output.txt
            echo "$BACKEND_AWS_PUBLIC_IP" >> .circleci/ansible/inventory.txt                 
            cat ~/output.txt                
      - persist_to_workspace:
          root: ~/
          paths:
            - project/.circleci/ansible/inventory.txt
            - output.txt
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
     
# -----------------------------  aws infra config  ---------------------  
#                fingerprint taken from ssh of circle ci  
#  ---------------------------------------------------------------------

  configure-infrastructure:
    <<: *dok_ansible
    environment: 
      MY_STEP_NAME: "Configure Infrastructure"     
    steps:
      - checkout
      - add_ssh_keys:
          fingerprints: ["f9:48:2a:a5:28:e1:a7:1e:39:17:b5:b9:64:8d:42:18"]
      - attach_workspace:
          at: ~/
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Install dependencies
          command: |
            apk add --update ansible            
      - run:
          name: Configure server
          command: |
            pwd
            cat .circleci/ansible/inventory.txt
            echo ENVIRONMENT=production >> "backend/.env"   
            echo TYPEORM_CONNECTION=postgres >> "backend/.env"
            echo TYPEORM_ENTITIES=./src/modules/domain/**/*.entity.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS=./src/migrations/*.ts >> "backend/.env"
            echo TYPEORM_MIGRATIONS_DIR=./src/migrations >> "backend/.env"
            echo NODE_ENV=production >> "backend/.env"
            echo TYPEORM_HOST=$TYPEORM_HOST >> "backend/.env"
            echo TYPEORM_PORT=$TYPEORM_PORT >> "backend/.env"
            echo TYPEORM_USERNAME=$TYPEORM_USERNAME >> "backend/.env"
            echo TYPEORM_PASSWORD=$TYPEORM_PASSWORD >> "backend/.env"
            echo TYPEORM_DATABASE=$TYPEORM_DATABASE >> "backend/.env"
            ansible-playbook -i .circleci/ansible/inventory.txt .circleci/ansible/configure-server.yml            
            cat backend/.env
            ls backend
      - persist_to_workspace:
          root: ~/
          paths:
            - project/backend
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
                      
# -----------------------------  migration  -----------------------------------------            
  run-migrations:
    <<: *dok_node
    environment: 
      MY_STEP_NAME: "Run Migrations"
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - run:
          name: Run migrations
          working_directory: ./backend
          command: |            
            npm install            
            npm run build
            npm run migrations >> migration_output.txt
            cat migration_output.txt    
      - run:
          name: store migration result in memstash
          working_directory: ./backend
          command: |
            if [grep -q "executed successfully" migration_output.txt]
            then
              echo "DB migration was successful"
              curl -H "Content-Type: text/plain" -H "token: 58c78a8b-64a1-4bd9-8527-e0f897b1d02a" --request PUT --data "db_success" https://api.memstash.io/values/migration_status_${CIRCLE_WORKFLOW_ID:0:7}
            else
              echo "DB migration failed, looks like already exists...moving on."
              curl -H "Content-Type: text/plain" -H "token: 58c78a8b-64a1-4bd9-8527-e0f897b1d02a" --request PUT --data "db_failure" https://api.memstash.io/values/migration_status_${CIRCLE_WORKFLOW_ID:0:7}
            fi
            echo "WorkflowID=${CIRCLE_WORKFLOW_ID:0:7}"                    
      - destroy-environment:          
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
          
          
# -----------------------------  Deployment of app begins here  ---------------------            
# -----------------------------  Deploy front-end  ----------------------------------
  deploy-frontend:
    <<: *dok_ansible
    environment: 
      MY_STEP_NAME: "Deploy Front-end"
    steps:
      - checkout
      - attach_workspace:
          at: ~/
      - run:
          name: Install dependencies
          command: |
            apk add --update curl nodejs npm
            apk add --update curl tar
            npm install webpack-dev-server -g
            npm install
            pip install awscli
      - run:
          name: Frame and put backend url to env file
          command: |
            export API_URL=`cat ~/output.txt`
            echo "API_URL: $API_URL"
            echo ENVIRONMENT=production >> "frontend/.env"
            echo NODE_ENV=production >> "frontend/.env"
            echo API_URL=$API_URL >> "frontend/.env"
      - run:
          name: Deploy frontend objects
          command: |
            cd ~/project/frontend
            npm i
            npm install typescript@rc
            npm run build
      - run:
          name: copy frontend package to aws s3 bucket
          command: |
            cd ~/project/frontend
            aws s3 cp dist s3://udapeople-${CIRCLE_WORKFLOW_ID:0:7} --recursive
      - persist_to_workspace:
          root: ~/
          paths:
            - project/frontend/dist
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
      - revert-migrations:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"     
 # -----------------------------  Deploy back-end  ----------------------------------                    
  deploy-backend:
    <<: *dok_ansible
    environment: 
      MY_STEP_NAME: "Deploy backend"       
    steps:
      - checkout
      - restore_cache:
          keys: [backend-build]
      - add_ssh_keys:
          fingerprints: ["f9:48:2a:a5:28:e1:a7:1e:39:17:b5:b9:64:8d:42:18"]
      - attach_workspace:
          at: ~/
      - run: 
          name: Install dependencies
          command: |
            apk add --update curl nodejs npm
            apk add --update ansible zip
            apk add --update openssh-client tar gzip
            pip install awscli
      - run:
          name: Build backend app
          command: |
            cd ~/project/backend
            ls
            cd ../
            cd backend/ && tar -zcvf ../backend.tar.gz . && cd - 
            mkdir -p ~/project/.circleci/ansible/roles/deploy/files/
            mv backend.tar.gz ~/project/.circleci/ansible/roles/deploy/files/
      - run:
          name: Deploy backend Setup EC2 instance & copy compiled backend to the EC2 instance
          command: |
            # ls ~/project/.circleci/ansible/roles/deploy/files/
            cd ~/project/backend
            ansible-galaxy install weareinteractive.environment
            cat ~/project/.circleci/ansible/inventory.txt
            ansible-playbook -i ~/project/.circleci/ansible/inventory.txt ~/project/.circleci/ansible/deploy-backend.yml
            ansible-playbook -i ~/project/.circleci/ansible/inventory.txt ~/project/.circleci/ansible/node-explorer.yml
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
      - revert-migrations:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}" 
   
# -----------------------------  Deploy complete  ----------------------------------

# -----------------------------  start of smoke testing after deployment  ----------------------------
  smoke-test:
    <<: *dok_ansible    
    environment: 
      MY_STEP_NAME: "Smoke Test"         
    steps:
      - checkout
      - attach_workspace:
          at: ~/
      - run:
          name: Install dependencies
          command: |
            apk add --update curl
            pip install awscli
      - run:
          name: retrive backend url
          command: |
            pwd
            cat .circleci/ansible/inventory.txt
            ls
            cat ~/output.txt
            export API_URL=`cat ~/output.txt`
            echo "API_URL: $API_URL"
      - run:
          name: backend smoke test
          command: |            
            if curl -s $API_URL/api/status
            then
              return 1
            else
              return 0
            fi
      - run:
          name: Frontend smoke test
          command: |
            if curl -s http://udapeople-${CIRCLE_WORKFLOW_ID:0:7}.s3-website.us-west-2.amazonaws.com/ | grep "Welcome"
            then
              return 0
            else
              return 1
            fi
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
      - revert-migrations:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
    
# -----------------------------  Cloud front distribution  ----------------------------

  cloudfront-update:
    <<: *dok_awscli
    environment: 
      MY_STEP_NAME: "Cloud front dis. update"
    steps:
      - checkout
      - run: yum -y install tar gzip
      - run:
          name: Update cloudfront distribution
          command: |
            export OLD_WORKFLOW_ID=$(aws cloudformation list-exports --query "Exports[?Name==\`WorkflowID\`].Value" --no-paginate --output text)
            echo "OLD_WORKFLOW_ID: $OLD_WORKFLOW_ID."
            export STACKS=($(aws cloudformation list-stacks --query "StackSummaries[*].StackName" \
              --stack-status-filter CREATE_COMPLETE --no-paginate --output text))
            printf '%s\n' "${STACKS[@]}"
            
            aws cloudformation deploy \
              --template-file .circleci/files/cloudfront.yml \
              --parameter-overrides WorkflowID="${CIRCLE_WORKFLOW_ID:0:7}" \
              --stack-name udapeople-prod-cloudfront
              
      - destroy-environment:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
      - revert-migrations:
          workflow_id: "${CIRCLE_WORKFLOW_ID:0:7}"
       
# -----------------------------  Clean up the mess dont want AWS to charge ----------------------------
  cleanup:
      docker:
        - image: cimg/base:2020.01
      steps:
        - checkout
        - aws-cli/setup
        - run:
            name: Remove old stacks and files
            command: |
              export OldWorkflowID=$(aws cloudformation \
                list-exports --query "Exports[?Name==\`WorkflowID\`].Value" \
                --no-paginate --output text)
                
              export STACKS=($(aws cloudformation list-stacks --query "StackSummaries[*].StackName" \
                --stack-status-filter CREATE_COMPLETE --no-paginate --output text))
                
              echo "Old Workflow ID: ${OldWorkflowID}"
              if [ "${OldWorkflowID}" != "<< pipeline.parameters.workflow-id >>" ]
              then
                aws s3 rm "s3://udapeople-${CIRCLE_WORKFLOW_ID:5:7}" --recursive
                aws cloudformation delete-stack --stack-name "udapeople-backend-${OldWorkflowID:5:7}"
                aws cloudformation delete-stack --stack-name "udapeople-frontend-${OldWorkflowID:5:7}"
              fi
  
# -------------------------------------------------------------------------------
#
#         WORKFLOW STEPS STARTS FROM HERE
#
# -------------------------------------------------------------------------------
workflows:
  default:
    jobs:
      - build-frontend
      - build-backend
      #- test-frontend:
      #    requires: [build-frontend]
      #- test-backend:
      #    requires: [build-backend]
      #- scan-frontend:
      #    requires: [build-frontend]
      #- scan-backend:
      #    requires: [build-backend]
      #- deploy-infrastructure:
      #    requires: [build-frontend, build-backend, test-frontend, test-backend, scan-frontend, scan-backend]
      #    filters:
      #      branches:
      #        only: [master]
      #- configure-infrastructure:
      #    requires: [deploy-infrastructure]
      #- run-migrations:
      #    requires: [configure-infrastructure]
      #- deploy-backend:
      #    requires: [run-migrations]           
      #- deploy-frontend:
      #    requires: [run-migrations, deploy-backend]
      #- smoke-test:
      #    requires: [deploy-backend, deploy-frontend]
      #- cloudfront-update:
      #    requires: [smoke-test]            
      # - cleanup:
      #     requires: [cloudfront-update]
      #  --------------------------  End of Job  ---------------------------------------- 
